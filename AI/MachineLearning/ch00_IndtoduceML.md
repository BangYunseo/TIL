# Chapter 0. 기계학습 소개

> '기계학습 - 오일석' 1장 학습 내용
>
> 0절. AI
>
> 1절. 기계학습
>
> 2절. 특징 공간
>
> 3절. 데이터
>
> 4절. 기계 학습 예시
>
> 5절. 모델 선택
>
> 6절. 규제
>
> 7절. 기계 학습 유형

## 0절. AI

### 인공지능

- 사고나 학습 등 인간이 가진 지적 능력을 컴퓨터로 구현한 기술
- 인간 or 인간 이상의 지식 상태 구현

### 머신러닝

- 컴퓨터가 스스로 학습하여 인공지능의 성능을 향상시키는 기술 방법
- 여러 가지 경우를 학습하여 그와 비슷한 경우의 문제 해결

### 딥러닝

- 인간의 뉴런과 비슷한 인공신경망 방식으로 정보 처리
- 상황에 적합한 학습 경험 이용

## 1절. 기계학습

### 학습

- 경험의 결과로 나타나는 비교적 지속적인 행동, 잠재력의 변화
- 지식을 습득하는 과정

### 기계학습

- <strong>사례 데이터, 과거 경험</strong>으로 성능 기준이 최적화된 프로그래밍 [Alpaydin, 2010]
- 성능을 개선하거나 정확하게 예측하기 위해 경험을 이용하는 계산학 방법 [Mohri, 2012]
- 데이터를 기반으로 인간처럼 응용하는 학습

### 기계학습으로의 전환

| 기간 |          요약          | 설명                                           |
| :--: | :--------------------: | :--------------------------------------------- |
| 초기 |    인공지능의 탄생     | 컴퓨터의 뛰어난 능력과 기대감의 지식 기반 방식 |
| 중기 | 인공지능의 주도권 전환 | 지식 기반 방식에서 기계학습 방식으로 전환      |
| 후기 |    인공지능의 발전     | ??                                             |

### 기계학습 이해

#### 회귀(Regression)

- 실수의 목표값

|  요소  | 설명          |
| :----: | :------------ |
| 가로축 | 특징          |
| 세로축 | 목표치        |
| 데이터 | 관측된 4개 점 |

<img src = "https://github.com/BangYunseo/TIL/blob/main/AI/MachineLearning/Image/ch00/01_Regression.PNG" height="auto"/>

#### 예측(prediction)

- 임의의 시간이 주어졌을 때 이동체의 위치 예측
- 회귀와 분류로 분리

| 종류 | 영문           | 분류값        |
| :--: | :------------- | :------------ |
| 회귀 | Regression     | 실수의 목표값 |
| 분류 | Classification | 부류값        |

### 훈련집합

- 관측된 4개의 점은 <strong>데이터</strong>이자 <strong>훈련집합</strong>

<img src = "https://github.com/BangYunseo/TIL/blob/main/AI/MachineLearning/Image/ch00/02_TrainingData.PNG" height="auto"/>

| 번호  | X 값  |     |     | 번호  | Y 값  |
| :---: | :---: | :-: | :-: | :---: | :---: |
| $x_1$ | (2.0) |     |     | $y_1$ | (3.0) |
| $x_2$ | (4.0) |     |     | $y_2$ | (4.0) |
| $x_3$ | (6.0) |     |     | $y_3$ | (5.0) |
| $x_4$ | (8.0) |     |     | $y_4$ | (6.0) |

### 데이터 모델링

- 데이터가 직선이므로 직선 모델 선택
- 직선 모델의 수식
  - 매개 변수 : $w$, $b$

| 차원  | 수식                    |
| :---: | :---------------------- |
| 1차원 | $y = wx + b$            |
| 2차원 | $y = w_1x^2 + w_2x + b$ |

### 기계학습 목적

- 가장 정확하고 예측 가능한 최적의 매개 변수 탐색
- 최적값을 모르는 상태에서 학습 시작
- 점차 성능 개선 후 최적에 도달
  - $f_1$ -> $f_2$ -> $f_3$ 까지 성능 개선
  - 최적 $f_3$
    - $w=0.5$
    - $b=2.0$

### 기계학습의 발전 방향

- 훈련 집합에 없는 새로운 샘플(테스트 샘플)에 대한 오류 최소화
- 새로운 샘플에 대한 높은 성능 일반화(Generalization)

### 기계학습 비교

|          기준          | 사람                            | 기계학습                               |
| :--------------------: | :------------------------------ | :------------------------------------- |
|       학습 과정        | 능동적                          | 수동적                                 |
|      데이터 형식       | 자연에 존재하는 그대로          | 일정한 형식에 맞춰 사람이 준비         |
| 동시 학습 가능 과업 수 | 여러 과업 학습                  | 하나의 과업                            |
| 학습 원리에 대한 지식  | 매우 제한적                     | 모든 과정이 공개적                     |
|      수학 의존도       | 매우 낮음                       | 매우 높음                              |
|       성능 평가        | 경우에 따라 객관적이거나 주관적 | 객관적(수치로 평가, ex : 정확률 99.9%) |
|          역사          | 수백만 년                       | 60년 가량                              |

## 2절. 특징 공간

### 차원 별 특징 공간

#### 1차원 특징 공간

<img src = "https://github.com/BangYunseo/TIL/blob/main/AI/MachineLearning/Image/ch00/03_1-Dimension.PNG.PNG" height="auto"/>

| 번호  | 표시값 |
| :---: | :----: |
| $x_1$ |  특징  |
|  $y$  | 목푯값 |

#### 2차원 특징 공간

<img src = "https://github.com/BangYunseo/TIL/blob/main/AI/MachineLearning/Image/ch00/04_2-Dimension.PNG" height="auto"/>

|      번호      |  표시값   |
| :------------: | :-------: |
|     $x_1$      |  특징 1   |
|     $x_2$      |  특징 2   |
| $(x_1, x_2)^T$ | 특징 벡터 |
|      $y$       |  목푯값   |

- 특징 벡터 예시
  - $x=(몸무게, 키)^T$, $y=bmi$
  - $x=(체온, 두통)^T$, $y=감기 여부$

### 다차원 특징 공간

- $d$-차원 데이터 특징 벡터
  - $x = (x_1, x_2, ..., x_d)^T$
  - 직선 모델 매개 변수 = $d + 1$

> $d$-차원 데이터 모델
>
> $y = w_1x_1 + w_2x_2 + ... + w_dx_d + b$

#### 2차 곡선 모델 예제

- 다차원 특징 공간에서의 2차 곡선 모델
- 매개 변수 = $d^2 + d + 1$
- 데이터셋 예시

| 데이터셋 | 매개 변수            |
| :------: | :------------------- |
|   Iris   | $d = 4$, 21개        |
|  MNIST   | $d = 784$, 615,441개 |

> 2차 $d$-차원 데이터 모델
>
> $y = w_1x^2_1 + w_2x^2_2 + ... + w_dx^2_d + w_{d+1}x_1x_2 + ... + w_{d^2}x_{d-1}x_d+w_{{d^2}+1}x_1+...+w_{{d^2}+d}x_d+b$

#### 다차원 특징 공간 예제

- 특징 많으면 목표값 정확도 감소
- 올바른 학습 불가

<img src = "https://github.com/BangYunseo/TIL/blob/main/AI/MachineLearning/Image/ch00/05_N-Dimension.PNG" height="auto"/>

## 3절. 데이터

### 데이터

- 과학 기술 발전 과정

<img src = "https://github.com/BangYunseo/TIL/blob/main/AI/MachineLearning/Image/ch00/06_Process.PNG" height="auto"/>

- 기계 학습
  - 기계 학습이 푸는 문제는 훨씬 복잡
    - ex : '8' 숫자 패턴과 '단추' 패턴의 다양한 변화 양상
  - 단순한 수학 공식으로 표현 불가능
  - 자동으로 모델을 찾아내는 과정 필요

#### 데이터 생성 과정

- 데이터 생성 과정을 완전히 아는 인위적 상황의 예제

  - 두 개의 주사위를 던져 나온 눈의 합이 $X$일 때 $y=(x-7)^2+1$ 점을 받는 게임
  - 데이터 생성 과정을 완전히 알고 있는 상황
  - 즉, 데이터의 결과값이 나오는 과정 자체를 인지하고 있는 경우
    - $X$를 알면 정확한 $Y$를 예측 가능
      - 실제 주사위를 던져 $X = {3, 10, 8, 5}$를 얻었다면, $Y = {17, 10, 2, 5}$
    - $X$의 발생 확률 $P(X)$를 정확하게 파악 가능
    - $P(X)$를 알고 있기 때문에 새로운 데이터 생성 가능

- 실제 기계 학습 문제의 경우
  - 데이터 생성 과정은 미지수
  - 그저 주어진 훈련 집합의 예측 모델 또는 생성 모델을 근사 추정

#### 데이터베이스의 중요성

- 데이터베이스의 품질

  - 주어진 응용에 맞는 충분히 다양한 데이터를 충분한 양만큼 수집
    - 추정 정확도 상승
    - ex : 정면 얼굴만 가진 데이터베이스로 학습 후 기운 얼굴에 대한 성능은 매우 낮게 측정
      - 즉, 주어진 응용 환경을 자세히 살핀 후 그에 맞는 데이터 확보가 필요

- 다양한 공개 데이터베이스
  - lris, MNIST, ImageNet
    - 기계 학습의 초파리로 여겨지는 3가지 데이터베이스
    - 위키피디아에서 'list of datasets for machine learning research'로 검색 가능
    - UCI Repository(622개 데이터베이스 제공)

####
